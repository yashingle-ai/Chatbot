from enum import Enum
from typing import Dict, Any

class ModelProvider(Enum):
    LOCAL = "local"
    GROQ = "groq"
    ANTHROPIC = "anthropic"
    OLLAMA = "ollama"
    OPENAI = "openai"
    TOGETHER = "together"

MODEL_CONFIGS: Dict[str, Dict[str, Any]] = {
    "local-mistral": {
        "provider": ModelProvider.LOCAL,
        "model_type": "mistral",
        "model_path": "F:/Wearables/Medical-RAG-LLM/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf",
        "config": {
            "max_new_tokens": 512,
            "context_length": 2048,
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 50,
        }
    },
    "groq-mixtral": {
        "provider": ModelProvider.GROQ,
        "model_id": "mixtral-8x7b-32768",
        "api_key": "YOUR_GROQ_API_KEY",
        "config": {
            "temperature": 0.7,
            "max_tokens": 1024,
        }
    },
    "anthropic-claude": {
        "provider": ModelProvider.ANTHROPIC,
        "model_id": "claude-3-opus-20240229",
        "api_key": "YOUR_ANTHROPIC_API_KEY",
        "config": {
            "temperature": 0.7,
            "max_tokens": 1024,
        }
    },
    "ollama-llama2": {
        "provider": ModelProvider.OLLAMA,
        "model_id": "llama2:70b",
        "config": {
            "temperature": 0.7,
            "max_tokens": 512,
        }
    },
    "openai-gpt4": {
        "provider": ModelProvider.OPENAI,
        "model_id": "gpt-4-turbo-preview",
        "api_key": "YOUR_OPENAI_API_KEY",
        "config": {
            "temperature": 0.7,
            "max_tokens": 1024,
        }
    },
    "together-yi": {
        "provider": ModelProvider.TOGETHER,
        "model_id": "yi:34b",
        "api_key": "YOUR_TOGETHER_API_KEY",
        "config": {
            "temperature": 0.7,
            "max_tokens": 1024,
        }
    }
}

REPORT_TEMPLATE = """
Based on our conversation, create a professional report covering these aspects:

Summary:
{summary}

Key Points Discussed:
{points}

Recommendations:
{recommendations}

Next Steps:
{next_steps}

This report was generated by {model_name} on {date}.
"""
